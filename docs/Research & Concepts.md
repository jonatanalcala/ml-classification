# Research & Concepts

In this section we will reflect on our results and cover key concepts regarding the models we worked with.

---

## A.) Feature Scaling: Why is important for gradient-based algorithms?


---

## B.) Gradient Descent Variants: Batch vs Stochastic Gradient Descent


--- 

## C.) Scikit-learn vs Book Implementations: Why does scikit-learn outperform book code?


---

## D.) Decision Boundaries: Comparing Logsitic Regression & SVM


---

## E.) Regularization: Preventing Overfitting in Machine Learning


---

## F.) Impact of the `C` Parameter: Logistic Regression & Linear SVC: 0.01, 1.0, 100.0

